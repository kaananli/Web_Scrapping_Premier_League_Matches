{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64SNR6cC9uQS"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bts\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from datetime import date\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_team_urls(standing_url):\n",
        "    data = requests.get(standing_url)\n",
        "    soup = bts(data.text)\n",
        "    standing_table = soup.select(\"table.stats_table\")[0]\n",
        "    links = standing_table.find_all(\"a\")\n",
        "    links = [l.get(\"href\") for l in links]\n",
        "    links = [l for l in links if '/squads/' in l]\n",
        "    team_urls = [f\"https://fbref.com{l}\" for l in links]\n",
        "    return team_urls, soup.select(\"a.prev\")[0].get(\"href\")\n",
        "\n",
        "def get_shooting_data(team_url):\n",
        "    data = requests.get(team_url)\n",
        "    soup = bts(data.text)\n",
        "    links = soup.find_all(\"a\")\n",
        "    links = [l.get(\"href\") for l in links]\n",
        "    links = [l for l in links if l and \"all_comps/shooting/\" in l]\n",
        "    data = requests.get(f\"https://fbref.com{links[0]}\")\n",
        "    try:\n",
        "        shooting_data = pd.read_html(data.text, match=\"Shooting\")[0]\n",
        "        shooting_data.columns = shooting_data.columns.droplevel()\n",
        "    except ValueError:\n",
        "        shooting_data = None\n",
        "    return shooting_data\n",
        "\n",
        "def clean_team_name(team_url):\n",
        "    team_name = team_url.split(\"/\")[-1].replace(\"-Stats\",\"\").replace(\"-\",\" \")\n",
        "    return team_name\n",
        "\n",
        "def fetch_data(year, standing_url):\n",
        "    all_matches = []\n",
        "    while standing_url is not None:\n",
        "        team_urls, standing_url = get_team_urls(standing_url)\n",
        "        for team_url in team_urls:\n",
        "            team_name = clean_team_name(team_url)\n",
        "            data = requests.get(team_url)\n",
        "            matches = pd.read_html(data.text, match=\"Scores & Fixtures\")[0]\n",
        "            shooting_data = get_shooting_data(team_url)\n",
        "            if shooting_data is None:\n",
        "                continue\n",
        "            try:\n",
        "                team_data = matches.merge(shooting_data[[\"Date\", \"Sh\", \"SoT\", \"Dist\",\"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n",
        "            except ValueError:\n",
        "                continue\n",
        "            team_data = team_data[team_data[\"Comp\"] == \"Premier League\"]\n",
        "            team_data[\"Season\"] = year\n",
        "            team_data[\"Team\"] = team_name\n",
        "            all_matches.append(team_data)\n",
        "            time.sleep(1)\n",
        "    return pd.concat(all_matches)\n",
        "years = range(2021, 2022)\n",
        "all_data = []\n",
        "for year in years:\n",
        "    standing_url = f\"https://fbref.com/en/comps/9/{year}-Premier-League-Stats\"\n",
        "    all_data.append(fetch_data(year, standing_url))"
      ],
      "metadata": {
        "id": "-BTBPphj9yMo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
